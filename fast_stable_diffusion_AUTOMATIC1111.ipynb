{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kV9o1Ni8GH"
      },
      "source": [
        "# **Colab Pro notebook from https://github.com/TheLastBen/fast-stable-diffusion** *Alternatives : [RunPod](https://www.runpod.io/console/gpu-browse?template=runpod-stable-unified)  | [Paperspace](https://console.paperspace.com/github/TheLastBen/PPS?machine=Free-GPU)*\n",
        "##**[Support](https://ko-fi.com/thelastben)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y9EBc437WDOs"
      },
      "outputs": [],
      "source": [
        "#@markdown # Connect Google Drive\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "Shared_Drive = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Leave empty if you're not using a shared drive\n",
        "\n",
        "print(\"\u001b[0;33mConnecting...\")\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "if Shared_Drive!=\"\" and os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  mainpth=\"Shareddrives/\"+Shared_Drive\n",
        "else:\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CFWtw-6EPrKi"
      },
      "outputs": [],
      "source": [
        "#@markdown # Install/Update AUTOMATIC1111 repo\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "import base64\n",
        "import gdown\n",
        "from gdown.download import get_url_from_gdrive_confirmation\n",
        "import requests\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.parse import urlparse, parse_qs, unquote\n",
        "from tqdm import tqdm\n",
        "import six\n",
        "\n",
        "\n",
        "blasphemy=base64.b64decode((\"ZWJ1aQ==\").encode('ascii')).decode('ascii')\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive\"):\n",
        "  print('\u001b[1;31mGdrive not connected, using temporary colab storage ...')\n",
        "  time.sleep(4)\n",
        "  mainpth=\"MyDrive\"\n",
        "  !mkdir -p /content/gdrive/$mainpth\n",
        "  Shared_Drive=\"\"\n",
        "\n",
        "if Shared_Drive!=\"\" and not os.path.exists(\"/content/gdrive/Shareddrives\"):\n",
        "  print('\u001b[1;31mShared drive not detected, using default MyDrive')\n",
        "  mainpth=\"MyDrive\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  def inf(msg, style, wdth): inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth));display(inf)\n",
        "  fgitclone = \"git clone --depth 1\"\n",
        "  %mkdir -p /content/gdrive/$mainpth/sd\n",
        "  %cd /content/gdrive/$mainpth/sd\n",
        "  !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-w$blasphemy\n",
        "  !mkdir -p /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/cache/\n",
        "  os.environ['TRANSFORMERS_CACHE']=f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blasphemy+\"/cache\"\n",
        "  os.environ['TORCH_HOME'] = f\"/content/gdrive/{mainpth}/sd/stable-diffusion-w\"+blasphemy+\"/cache\"\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/\n",
        "  !git reset --hard\n",
        "  !git checkout master\n",
        "  time.sleep(1)\n",
        "  !rm webui.sh\n",
        "  !git pull\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZGV_5H4xrOSp"
      },
      "outputs": [],
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/\n",
        "  !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/A1111.txt\n",
        "  !dpkg -i *.deb\n",
        "  if not os.path.exists('/content/gdrive/'+mainpth+'/sd/stablediffusiond'): #restore later\n",
        "    !tar -C /content/gdrive/$mainpth --zstd -xf sd_mrep.tar.zst\n",
        "  !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
        "  !rm *.deb | rm *.zst | rm *.txt\n",
        "  if not os.path.exists('gdrive/'+mainpth+'/sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
        "    %env CXXFLAGS=-std=c++14\n",
        "    !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
        "    !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
        "    %cd /content/gperftools\n",
        "    !patch -p1 < /content/Patch\n",
        "    !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
        "    !mkdir -p /content/gdrive/$mainpth/sd/libtcmalloc && cp .libs/libtcmalloc*.so* /content/gdrive/$mainpth/sd/libtcmalloc\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "    %cd /content\n",
        "    !rm *.tar.gz Patch && rm -r /content/gperftools\n",
        "  else:\n",
        "    %env LD_PRELOAD=/content/gdrive/$mainpth/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
        "  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "  os.environ['PYTHONWARNINGS'] = 'ignore'\n",
        "  !sed -i 's@text = _formatwarnmsg(msg)@text =\\\"\\\"@g' /usr/lib/python3.10/warnings.py\n",
        "  !pip install open-clip-torch==2.20.0 -qq --no-deps\n",
        "  !pip install fastapi==0.94.0 -qq\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p4wj_txjP3TC"
      },
      "outputs": [],
      "source": [
        "#@markdown # Model Download/Load\n",
        "\n",
        "Use_Temp_Storage = False #@param {type:\"boolean\"}\n",
        "#@markdown - If not, make sure you have enough space on your gdrive\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "Model_Version = \"SDXL\" #@param [\"SDXL\", \"1.5\", \"v1.5 Inpainting\", \"V2.1-768px\"]\n",
        "\n",
        "#@markdown Or\n",
        "PATH_to_MODEL = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Insert the full path of your custom model or to a folder containing multiple models\n",
        "\n",
        "#@markdown Or\n",
        "MODEL_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "def getsrc(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if parsed_url.netloc == 'civitai.com':\n",
        "        src='civitai'\n",
        "    elif parsed_url.netloc == 'drive.google.com':\n",
        "        src='gdrive'\n",
        "    elif parsed_url.netloc == 'huggingface.co':\n",
        "        src='huggingface'\n",
        "    else:\n",
        "        src='others'\n",
        "    return src\n",
        "\n",
        "src=getsrc(MODEL_LINK)\n",
        "\n",
        "def get_name(url, gdrive):\n",
        "    if not gdrive:\n",
        "        response = requests.get(url, allow_redirects=False)\n",
        "        if \"Location\" in response.headers:\n",
        "            redirected_url = response.headers[\"Location\"]\n",
        "            quer = parse_qs(urlparse(redirected_url).query)\n",
        "            if \"response-content-disposition\" in quer:\n",
        "                disp_val = quer[\"response-content-disposition\"][0].split(\";\")\n",
        "                for vals in disp_val:\n",
        "                    if vals.strip().startswith(\"filename=\"):\n",
        "                        filenm=unquote(vals.split(\"=\", 1)[1].strip())\n",
        "                        return filenm.replace(\"\\\"\",\"\")\n",
        "    else:\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"}\n",
        "        lnk=\"https://drive.google.com/uc?id={id}&export=download\".format(id=url[url.find(\"/d/\")+3:url.find(\"/view\")])\n",
        "        res = requests.session().get(lnk, headers=headers, stream=True, verify=True)\n",
        "        res = requests.session().get(get_url_from_gdrive_confirmation(res.text), headers=headers, stream=True, verify=True)\n",
        "        content_disposition = six.moves.urllib_parse.unquote(res.headers[\"Content-Disposition\"])\n",
        "        filenm = re.search(r\"filename\\*=UTF-8''(.*)\", content_disposition).groups()[0].replace(os.path.sep, \"_\")\n",
        "        return filenm\n",
        "\n",
        "\n",
        "def dwn(url, dst, msg):\n",
        "    file_size = None\n",
        "    req = Request(url, headers={\"User-Agent\": \"torch.hub\"})\n",
        "    u = urlopen(req)\n",
        "    meta = u.info()\n",
        "    if hasattr(meta, 'getheaders'):\n",
        "        content_length = meta.getheaders(\"Content-Length\")\n",
        "    else:\n",
        "        content_length = meta.get_all(\"Content-Length\")\n",
        "    if content_length is not None and len(content_length) > 0:\n",
        "        file_size = int(content_length[0])\n",
        "\n",
        "    with tqdm(total=file_size, disable=False, mininterval=0.5,\n",
        "              bar_format=msg+' |{bar:20}| {percentage:3.0f}%') as pbar:\n",
        "        with open(dst, \"wb\") as f:\n",
        "            while True:\n",
        "                buffer = u.read(8192)\n",
        "                if len(buffer) == 0:\n",
        "                    break\n",
        "                f.write(buffer)\n",
        "                pbar.update(len(buffer))\n",
        "            f.close()\n",
        "\n",
        "\n",
        "def sdmdls(ver, Use_Temp_Storage):\n",
        "\n",
        "  if ver=='1.5':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v1-5-pruned-emaonly.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blasphemy+'/models/Stable-diffusion/v1-5-pruned-emaonly.safetensors'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors'\n",
        "  elif ver=='V2.1-768px':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/v2-1_768-ema-pruned.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blasphemy+'/models/Stable-diffusion/v2-1_768-ema-pruned.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors'\n",
        "  elif ver=='v1.5 Inpainting':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd-v1-5-inpainting.ckpt'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blasphemy+'/models/Stable-diffusion/sd-v1-5-inpainting.ckpt'\n",
        "    link='https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt'\n",
        "  elif ver=='SDXL':\n",
        "    if Use_Temp_Storage:\n",
        "      os.makedirs('/content/temp_models', exist_ok=True)\n",
        "      model='/content/temp_models/sd_xl_base_1.0.safetensors'\n",
        "    else:\n",
        "      model='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blasphemy+'/models/Stable-diffusion/sd_xl_base_1.0.safetensors'\n",
        "    link='https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors'\n",
        "\n",
        "  if not os.path.exists(model):\n",
        "    !gdown --fuzzy -O $model $link\n",
        "    if os.path.exists(model):\n",
        "      clear_output()\n",
        "      inf('\\u2714 Done','success', '50px')\n",
        "    else:\n",
        "      inf('\\u2718 Something went wrong, try again','danger', \"250px\")\n",
        "  else:\n",
        "      clear_output()\n",
        "      inf('\\u2714 Model already exists','primary', '300px')\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "if (PATH_to_MODEL !=''):\n",
        "  if os.path.exists(str(PATH_to_MODEL)):\n",
        "    inf('\\u2714 Using the trained model.','success', '200px')\n",
        "\n",
        "  else:\n",
        "      while not os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2718 Wrong path, use the colab file explorer to copy the path : ','danger', \"400px\")\n",
        "        PATH_to_MODEL=input()\n",
        "      if os.path.exists(str(PATH_to_MODEL)):\n",
        "        inf('\\u2714 Using the custom model.','success', '200px')\n",
        "\n",
        "  model=PATH_to_MODEL\n",
        "\n",
        "elif MODEL_LINK != \"\":\n",
        "\n",
        "      if src=='civitai':\n",
        "         modelname=get_name(MODEL_LINK, False)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blasphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            dwn(MODEL_LINK, model, 'Downloading the custom model')\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      elif src=='gdrive':\n",
        "         modelname=get_name(MODEL_LINK, True)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blasphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '300px')\n",
        "      else:\n",
        "         modelname=os.path.basename(MODEL_LINK)\n",
        "         if Use_Temp_Storage:\n",
        "            os.makedirs('/content/temp_models', exist_ok=True)\n",
        "            model=f'/content/temp_models/{modelname}'\n",
        "         else:\n",
        "            model=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blasphemy}/models/Stable-diffusion/{modelname}'\n",
        "         if not os.path.exists(model):\n",
        "            gdown.download(url=MODEL_LINK, output=model, quiet=False, fuzzy=True)\n",
        "            clear_output()\n",
        "         else:\n",
        "            inf('\\u2714 Model already exists','primary', '700px')\n",
        "\n",
        "      if os.path.exists(model) and os.path.getsize(model) > 1810671599:\n",
        "        inf('\\u2714 Model downloaded, using the custom model.','success', '300px')\n",
        "      else:\n",
        "        !rm model\n",
        "        inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "else:\n",
        "  model=sdmdls(Model_Version, Use_Temp_Storage)\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Svx6Hx0iUPd1"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download LoRA\n",
        "\n",
        "LoRA_LINK = \"\" #@param {type:\"string\"}\n",
        "\n",
        "os.makedirs('/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blasphemy+'/models/Lora', exist_ok=True)\n",
        "\n",
        "src=getsrc(LoRA_LINK)\n",
        "\n",
        "if src=='civitai':\n",
        "    modelname=get_name(LoRA_LINK, False)\n",
        "    loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blasphemy}/models/Lora/{modelname}'\n",
        "    if not os.path.exists(loramodel):\n",
        "      dwn(LoRA_LINK, loramodel, 'Downloading the LoRA model '+modelname)\n",
        "      clear_output()\n",
        "    else:\n",
        "      inf('\\u2714 Model already exists','primary', '300px')\n",
        "elif src=='gdrive':\n",
        "    modelname=get_name(LoRA_LINK, True)\n",
        "    loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blasphemy}/models/Lora/{modelname}'\n",
        "    if not os.path.exists(loramodel):\n",
        "      gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "      clear_output()\n",
        "    else:\n",
        "      inf('\\u2714 Model already exists','primary', '300px')\n",
        "else:\n",
        "    modelname=os.path.basename(LoRA_LINK)\n",
        "    loramodel=f'/content/gdrive/{mainpth}/sd/stable-diffusion-w{blasphemy}/models/Lora/{modelname}'\n",
        "    if not os.path.exists(loramodel):\n",
        "      gdown.download(url=LoRA_LINK, output=loramodel, quiet=False, fuzzy=True)\n",
        "      clear_output()\n",
        "    else:\n",
        "      inf('\\u2714 Model already exists','primary', '700px')\n",
        "\n",
        "if os.path.exists(loramodel) :\n",
        "  inf('\\u2714 LoRA downloaded','success', '300px')\n",
        "else:\n",
        "  inf('\\u2718 Wrong link, check that the link is valid','danger', \"300px\")\n",
        "\n",
        "#@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zC3Rz1b2TBcB"
      },
      "outputs": [],
      "source": [
        "#@markdown # ControlNet\n",
        "from torch.hub import download_url_to_file\n",
        "from urllib.parse import urlparse\n",
        "import re\n",
        "from subprocess import run\n",
        "\n",
        "Model = \"None\" #@param [ \"None\", \"All (21GB)\", \"Canny\", \"Depth\", \"Lineart\", \"MLSD\", \"Normal\", \"OpenPose\", \"Scribble\", \"Seg\", \"ip2p\", \"Shuffle\", \"Inpaint\", \"Softedge\", \"Lineart_Anime\", \"Tile\", \"T2iadapter_Models\"]\n",
        "\n",
        "v2_Model = \"None\" #@param [ \"None\", \"All\", \"Canny\", \"Depth\", \"HED\", \"OpenPose\", \"Scribble\"]\n",
        "\n",
        "#@markdown - Download/update ControlNet extension and its models\n",
        "\n",
        "def download(url, model_dir):\n",
        "\n",
        "    filename = os.path.basename(urlparse(url).path)\n",
        "    pth = os.path.abspath(os.path.join(model_dir, filename))\n",
        "    if not os.path.exists(pth):\n",
        "        print('Downloading: '+os.path.basename(url))\n",
        "        download_url_to_file(url, pth, hash_prefix=None, progress=True)\n",
        "    else:\n",
        "      print(f\"\u001b[1;32mThe model {filename} already exists\u001b[0m\")\n",
        "\n",
        "Canny='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth'\n",
        "Depth='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth.pth'\n",
        "Lineart='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart.pth'\n",
        "MLSD='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd.pth'\n",
        "Normal='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae.pth'\n",
        "OpenPose='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose.pth'\n",
        "Scribble='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble.pth'\n",
        "Seg='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg.pth'\n",
        "ip2p='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p.pth'\n",
        "Shuffle='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle.pth'\n",
        "Inpaint='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint.pth'\n",
        "Softedge='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge.pth'\n",
        "Lineart_Anime='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime.pth'\n",
        "Tile='https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile.pth'\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/extensions\n",
        "  if not os.path.exists(\"sd-webui-controlnet\"):\n",
        "    !git clone https://github.com/Mikubill/sd-w$blasphemy-controlnet.git\n",
        "    %cd /content\n",
        "  else:\n",
        "    %cd sd-w$blasphemy-controlnet\n",
        "    !git reset --hard\n",
        "    !git pull\n",
        "    %cd /content\n",
        "\n",
        "mdldir='/content/gdrive/'+mainpth+'/sd/stable-diffusion-w'+blasphemy+'/extensions/sd-w'+blasphemy+'-controlnet/models'\n",
        "for filename in os.listdir(mdldir):\n",
        "  if \"_sd14v1\" in filename:\n",
        "    renamed = re.sub(\"_sd14v1\", \"-fp16\", filename)\n",
        "    os.rename(os.path.join(mdldir, filename), os.path.join(mdldir, renamed))\n",
        "\n",
        "!wget -q -O CN_models.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models.txt\n",
        "!wget -q -O CN_models_v2.txt https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/CN_models_v2.txt\n",
        "\n",
        "with open(\"CN_models.txt\", 'r') as f:\n",
        "  mdllnk = f.read().splitlines()\n",
        "with open(\"CN_models_v2.txt\", 'r') as d:\n",
        "  mdllnk_v2 = d.read().splitlines()\n",
        "\n",
        "!rm CN_models.txt CN_models_v2.txt\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  cfgnames=[os.path.basename(url).split('.')[0]+'.yaml' for url in mdllnk_v2]\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/extensions/sd-w$blasphemy-controlnet/models\n",
        "  for name in cfgnames:\n",
        "      run(['cp', 'cldm_v21.yaml', name])\n",
        "  %cd /content\n",
        "\n",
        "if Model == \"All (21GB)\":\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif Model == \"T2iadapter_Models\":\n",
        "  mdllnk=list(filter(lambda x: 't2i' in x, mdllnk))\n",
        "  for lnk in mdllnk:\n",
        "      download(lnk, mdldir)\n",
        "  clear_output()\n",
        "\n",
        "elif Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "\n",
        "else:\n",
        "  download(globals()[Model], mdldir)\n",
        "  clear_output()\n",
        "\n",
        "Canny='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_canny.safetensors'\n",
        "Depth='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_depth.safetensors'\n",
        "HED='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_hed.safetensors'\n",
        "OpenPose='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_openposev2.safetensors'\n",
        "Scribble='https://huggingface.co/thibaud/controlnet-sd21/resolve/main/control_v11p_sd21_scribble.safetensors'\n",
        "\n",
        "if v2_Model == \"All\":\n",
        "  for lnk_v2 in mdllnk_v2:\n",
        "      download(lnk_v2, mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "elif v2_Model == \"None\":\n",
        "    pass\n",
        "    clear_output()\n",
        "    inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "else:\n",
        "  download(globals()[v2_Model], mdldir)\n",
        "  clear_output()\n",
        "  inf('\\u2714 Done','success', '50px')\n",
        "\n",
        "  #@markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PjzwxTkPSPHf"
      },
      "outputs": [],
      "source": [
        "#@markdown # Start Stable-Diffusion\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "import sys\n",
        "import fileinput\n",
        "from pyngrok import ngrok, conf\n",
        "import re\n",
        "\n",
        "\n",
        "Use_Cloudflare_Tunnel = False #@param {type:\"boolean\"}\n",
        "#@markdown - Offers better gradio responsivity\n",
        "\n",
        "Ngrok_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - Input your ngrok token if you want to use ngrok server\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password= \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional)\n",
        "\n",
        "auth=f\"--gradio-auth {User}:{Password}\"\n",
        "if User ==\"\" or Password==\"\":\n",
        "  auth=\"\"\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/modules/\n",
        "  !wget -q -O extras.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blasphemy/master/modules/extras.py\n",
        "  !wget -q -O sd_models.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-w$blasphemy/master/modules/sd_models.py\n",
        "  !wget -q -O /usr/local/lib/python3.10/dist-packages/gradio/blocks.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/blocks.py\n",
        "  %cd /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/\n",
        "  \n",
        "  !sed -i 's@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title@shared.opts.data\\[\"sd_model_checkpoint\"] = checkpoint_info.title;model.half()@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/modules/sd_models.py\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/webui.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/modules/extras.py\n",
        "\n",
        "  !sed -i 's@possible_sd_paths =.*@possible_sd_paths = [\\\"/content/gdrive/{mainpth}/sd/stablediffusion\\\"]@' /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/modules/paths.py\n",
        "  !sed -i 's@\\.\\.\\/@src/@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/modules/paths.py\n",
        "  !sed -i 's@src/generative-models@generative-models@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/modules/paths.py\n",
        "\n",
        "  !sed -i 's@print(\\\"No module.*@@' /content/gdrive/$mainpth/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
        "  !sed -i 's@\\[\"sd_model_checkpoint\"\\]@\\[\"sd_model_checkpoint\", \"sd_vae\", \"CLIP_stop_at_last_layers\", \"inpainting_mask_weight\", \"initial_noise_multiplier\"\\]@g' /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/modules/shared.py\n",
        "\n",
        "share=''\n",
        "if Ngrok_token!=\"\":\n",
        "  ngrok.kill()\n",
        "  srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "\n",
        "  for line in fileinput.input('/usr/local/lib/python3.10/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "    if line.strip().startswith('self.protocol = \"https\"'):\n",
        "        line = '            self.protocol = \"https\"\\n'\n",
        "    if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "        line = ''\n",
        "    if line.strip().startswith('else \"http\"'):\n",
        "        line = ''\n",
        "    sys.stdout.write(line)\n",
        "\n",
        "elif Use_Cloudflare_Tunnel:\n",
        "  with capture.capture_output() as cap:\n",
        "    !pkill cloudflared\n",
        "    time.sleep(4)\n",
        "    !nohup cloudflared tunnel --url http://localhost:7860 > /content/srv.txt 2>&1 &\n",
        "    time.sleep(4)\n",
        "    with open('/content/srv.txt', \"r\") as file: text = file.read()\n",
        "    srv= re.findall(r\"https?://(?:\\S+?\\.)?trycloudflare\\.com\\S*\", text)[0]\n",
        "\n",
        "    for line in fileinput.input('/usr/local/lib/python3.10/dist-packages/gradio/blocks.py', inplace=True):\n",
        "      if line.strip().startswith('self.server_name ='):\n",
        "          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "      if line.strip().startswith('self.protocol = \"https\"'):\n",
        "          line = '            self.protocol = \"https\"\\n'\n",
        "      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "          line = ''\n",
        "      if line.strip().startswith('else \"http\"'):\n",
        "          line = ''\n",
        "      sys.stdout.write(line)\n",
        "\n",
        "    !rm /content/srv.txt\n",
        "\n",
        "else:\n",
        "  share='--share'\n",
        "\n",
        "ckptdir=''\n",
        "if os.path.exists('/content/temp_models'):\n",
        "  ckptdir='--ckpt-dir /content/temp_models'\n",
        "\n",
        "try:\n",
        "  model\n",
        "  if os.path.isfile(model):\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt \"$model\" --xformers $auth --disable-console-progressbars --upcast-sampling $ckptdir\n",
        "  else:\n",
        "    !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae  --ckpt-dir \"$model\" --xformers $auth --disable-console-progressbars --upcast-sampling\n",
        "except:\n",
        "   !python /content/gdrive/$mainpth/sd/stable-diffusion-w$blasphemy/webui.py $share --api --disable-safe-unpickle --enable-insecure-extension-access --no-download-sd-model --no-half-vae --xformers $auth --disable-console-progressbars --upcast-sampling $ckptdir"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
