{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kV9o1Ni8GH"
      },
      "source": [
        "# **Colab From https://github.com/TheLastBen/fast-stable-diffusion, if you have any issues, feel free to discuss them.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9EBc437WDOs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Google Drive\n",
        "#@markdown # Do you want to use google drive?\n",
        "\n",
        "use_gdrive = False #@param {type:\"boolean\"}\n",
        "#@markdown Note: Google Drive only works on Google Colab hosted runtimes\n",
        "if use_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  working_dir = '/content/gdrive/MyDrive'\n",
        "\n",
        "\n",
        "else:\n",
        "  import os\n",
        "  working_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFWtw-6EPrKi"
      },
      "outputs": [],
      "source": [
        "#@markdown # Installing hlky repo\n",
        "%%capture\n",
        "%cd $working_dir\n",
        "!git clone https://github.com/sd-webui/stable-diffusion-webui\n",
        "%cd $working_dir/stable-diffusion-webui/\n",
        "!mkdir -p cache/{huggingface,torch}\n",
        "%cd $working_dir/\n",
        "!ln -s $working_dir/stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
        "!ln -s $working_dir/stable-diffusion-webui/cache/torch ../root/.cache/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4wj_txjP3TC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74722c4-3de1-491e-a92b-b28bd13175e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully downloaded\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#@markdown # Model Download/Load\n",
        "token = \"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\" #@param {type:\"string\"}\n",
        "Redownload_the_original_model = False #@param {type:\"boolean\"}\n",
        "if Redownload_the_original_model:\n",
        "  %cd $working_dir/stable-diffusion-webui/models/ldm/stable-diffusion-v1\n",
        "  !wget -q -O model.ckpt https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py\n",
        "  !mv $working_dir/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt $working_dir/stable-diffusion-webui/models/ldm/stable-diffusion-v1/trashfile.f\n",
        "  time.sleep(2)\n",
        "  !rm $working_dir/stable-diffusion-webui/models/ldm/stable-diffusion-v1/trashfile.f\n",
        "  time.sleep(2)\n",
        "  clear_output()\n",
        "  \n",
        "#@markdown Or\n",
        "Path_to_trained_model = \"\" #@param {type:\"string\"}\n",
        "#@markdown Insert the full path of your trained model (eg: /content/gdrive/MyDrive/zarathustra.ckpt) and it will automatically be placed in the right place, otherwise, leave it EMPTY (make sure there are no spaces in the path)\n",
        "if (Path_to_trained_model !=''):\n",
        "  if os.path.exists(str(Path_to_trained_model)):\n",
        "    clear_output()\n",
        "    !cp $Path_to_trained_model f'{working_dir}/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt'\n",
        "    if os.path.exists(f'{working_dir}/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt'):\n",
        "      print('Model placed in the right directory')\n",
        "    else:\n",
        "      print('Something went wrong')\n",
        "  else:\n",
        "    print('Wrong path, use the colab file explorer to copy the path')\n",
        "\n",
        "else:\n",
        "\n",
        "\n",
        "  if token == \"\" and not os.path.exists(f'{working_dir}/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt'):\n",
        "    token=input(\"Insert your huggingface token :\")\n",
        "    %cd $working_dir/\n",
        "    !git init\n",
        "    !git lfs install --system --skip-repo\n",
        "    !git remote add -f origin \"https://USER:{token}@huggingface.co/CompVis/stable-diffusion-v-1-4-original\"\n",
        "    !git config core.sparsecheckout true\n",
        "    !echo \"sd-v1-4.ckpt\" > .git/info/sparse-checkout\n",
        "    !git pull origin main\n",
        "    !mv $working_dir/sd-v1-4.ckpt $working_dir/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt\n",
        "    if os.path.exists(f'{working_dir}/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt'):\n",
        "      clear_output()\n",
        "      print(\"Model successfully downloaded\")  \n",
        "\n",
        "  elif not os.path.exists(f'{working_dir}/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt'):\n",
        "        %cd $working_dir/\n",
        "        !git init\n",
        "        !git lfs install --system --skip-repo\n",
        "        !git remote add -f origin \"https://USER:{token}@huggingface.co/CompVis/stable-diffusion-v-1-4-original\"\n",
        "        !git config core.sparsecheckout true\n",
        "        !echo \"sd-v1-4.ckpt\" > .git/info/sparse-checkout\n",
        "        !git pull origin main\n",
        "        !mv $working_dir/sd-v1-4.ckpt $working_dir/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt\n",
        "        if os.path.exists(f'{working_dir}/stable-diffusion-webui/models/ldm/stable-diffusion-v1/model.ckpt'):\n",
        "          clear_output()\n",
        "          print(\"Model successfully downloaded\")  \n",
        "  else:\n",
        "      print(\"Model already exists\")\n",
        "\n",
        "  if os.path.exists(f'{working_dir}/.git'):\n",
        "    !rm -r $working_dir/.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGV_5H4xrOSp"
      },
      "outputs": [],
      "source": [
        "#@markdown # Installing Requirements\n",
        "import os\n",
        "from IPython.utils import capture\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  if not os.path.exists(f'{working_dir}/stable-diffusion-webui/arial.ttf'):\n",
        "    !wget https://github.com/matomo-org/travis-scripts/blob/master/fonts/Arial.ttf?raw=true -O $working_dir/stable-diffusion-webui/arial.ttf\n",
        "    !sudo apt-get install fonts-dejavu\n",
        "    !sudo fc-cache\n",
        "\n",
        "with capture.capture_output() as cap:     \n",
        "  if not os.path.exists(f'{working_dir}/stable-diffusion-webui/src/taming-transformers/taming'):\n",
        "    !mkdir $working_dir/stable-diffusion-webui/src\n",
        "    %cd $working_dir/stable-diffusion-webui/src\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !cp -R $working_dir/stable-diffusion-webui/src/taming-transformers/taming $working_dir/stable-diffusion-webui/scripts\n",
        "    !git clone https://github.com/openai/CLIP\n",
        "    !mv $working_dir/stable-diffusion-webui/src/CLIP/ $working_dir/stable-diffusion-webui/src/clip\n",
        "    !mv $working_dir/stable-diffusion-webui/src/clip/clip $working_dir/stable-diffusion-webui/scripts\n",
        "    !git clone https://github.com/hlky/k-diffusion-sd\n",
        "    !mv $working_dir/stable-diffusion-webui/src/k-diffusion-sd $working_dir/stable-diffusion-webui/src/k-diffusion\n",
        "    !cp -R $working_dir/stable-diffusion-webui/src/k-diffusion/k_diffusion $working_dir/stable-diffusion-webui/scripts\n",
        "    !git clone  https://github.com/devilismyfriend/latent-diffusion\n",
        "    !cp -R $working_dir/stable-diffusion-webui/ldm $working_dir/stable-diffusion-webui/scripts/ldm\n",
        "    !cp -R $working_dir/stable-diffusion-webui/optimizedSD $working_dir/stable-diffusion-webui/scripts\n",
        "    !cp -R $working_dir/stable-diffusion-webui/frontend $working_dir/stable-diffusion-webui/scripts\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd $working_dir/\n",
        "  !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_HLKY\n",
        "  !mv Dependencies_HLKY Dependencies_HLKY.7z\n",
        "  !7z x Dependencies_HLKY.7z\n",
        "  time.sleep(3)\n",
        "  !cp -r $working_dir/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "  !rm -r $working_dir/usr\n",
        "  !rm Dependencies_HLKY.7z\n",
        "  %cd $working_dir/stable-diffusion-webui/scripts/ldm/modules\n",
        "  !wget -O attention.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdJ3u4idUYZf"
      },
      "outputs": [],
      "source": [
        "#@markdown # GFGAN + ESRGAN + LDSR models download\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "LDSR = False #@param {type:\"boolean\"}\n",
        "\n",
        "if not os.path.exists(f'{working_dir}/stable-diffusion-webui/models/gfpgan/GFPGANv1.3.pth'):\n",
        "  !mkdir $working_dir/stable-diffusion-webui/models/gfpgan\n",
        "  %cd $working_dir/stable-diffusion-webui/models/gfpgan\n",
        "  !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\n",
        "  clear_output()\n",
        "\n",
        "if not os.path.exists(f'{working_dir}/stable-diffusion-webui/models/realesrgan/RealESRGAN_x4plus.pth'):\n",
        "  !mkdir $working_dir/stable-diffusion-webui/models/realesrgan\n",
        "  %cd $working_dir/stable-diffusion-webui/models/realesrgan\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\n",
        "  clear_output()\n",
        "\n",
        "if LDSR:\n",
        "  if not os.path.exists('/stable-diffusion-webui/models/ldsr/model.ckpt'):\n",
        "    !mkdir $working_dir/stable-diffusion-webui/models/ldsr\n",
        "    %cd $working_dir/stable-diffusion-webui/models/ldsr\n",
        "    !wget -O project.yaml https://heibox.uni-heidelberg.de/f/31a76b13ea27482981b4/?dl=1\n",
        "    clear_output()\n",
        "    !wget -O model.ckpt https://heibox.uni-heidelberg.de/f/578df07c8fc04ffbadf3/?dl=1\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a---cT2rwUQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d57247-08b6-46cd-fbb9-849e4b07c159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE !\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Installing xformers\n",
        "import os\n",
        "import time\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('It seems that your GPU is not supported at the moment, sorry.')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl  \n",
        "\n",
        "clear_output()\n",
        "print('DONE !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjzwxTkPSPHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c651bb2c-5c96-4ad7-da9f-1f1aeffa5d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GFPGAN\n",
            "Found RealESRGAN\n",
            "LDSR not found at path, please make sure you have cloned the LDSR repo to ./models/ldsr/\n",
            "Loading model from models/ldm/stable-diffusion-v1/model.ckpt\n",
            "Global Step: 470000\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla' with 512 in_channels\n",
            "Downloading: \"https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth\" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth\n",
            "100% 5.10M/5.10M [00:00<00:00, 73.2MB/s]\n",
            "Downloading: 100% 939k/939k [00:00<00:00, 6.96MB/s]\n",
            "Downloading: 100% 512k/512k [00:00<00:00, 3.94MB/s]\n",
            "Downloading: 100% 389/389 [00:00<00:00, 330kB/s]\n",
            "Downloading: 100% 905/905 [00:00<00:00, 959kB/s]\n",
            "Downloading: 100% 4.41k/4.41k [00:00<00:00, 2.94MB/s]\n",
            "Downloading: 100% 1.59G/1.59G [00:39<00:00, 43.0MB/s]\n",
            "Running on local URL:  https://loud-clubs-smile-35-202-22-168.loca.lt:443\n",
            "\u001b[32mConnected\n",
            "[MemMon] Recording max memory usage...\n",
            "\n",
            "Iteration: 1/1\n",
            "Current prompt: A cold-war-era warning message being played across a radio\n",
            " 12% 6/50 [00:04<00:16,  2.60it/s]"
          ]
        }
      ],
      "source": [
        "#@markdown # Start stable-diffusion\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "import time\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd $working_dir/stable-diffusion-webui/scripts\n",
        "  time.sleep(1)\n",
        "  !wget -O webui.py https://raw.githubusercontent.com/sd-webui/stable-diffusion-webui/master/scripts/webui.py\n",
        "  !sed -i 's@demo.queue(concur.*@demo.queue(concurrency_count=111500)@' $working_dir/stable-diffusion-webui/scripts/webui.py\n",
        "Use_Gradio_Server = False #@param {type:\"boolean\"}\n",
        "#@markdown  - Only if you have trouble connecting to the local server\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd $working_dir\n",
        "\n",
        "share=''\n",
        "if Use_Gradio_Server:\n",
        "  share='--share'\n",
        "  !sed -i '1037s@.*@            self.server_name = server_name@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = server_port@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\" if self.local_url.startswith(\"https\") else \"http\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "\n",
        "else:\n",
        "  share=''\n",
        "\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' $working_dir/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput(f'cat {working_dir}/srvr.txt')\n",
        "\n",
        "  !sed -i '1037s@.*@            self.server_name = \"{srv[8:]}\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = 443@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "          \n",
        "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "  \n",
        "  !rm $working_dir/srv.txt\n",
        "  !rm $working_dir/srvr.txt\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd $working_dir/stable-diffusion-webui/\n",
        "\n",
        "!python $working_dir/stable-diffusion-webui/scripts/webui.py $share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
